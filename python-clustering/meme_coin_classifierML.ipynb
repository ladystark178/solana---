{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据概览:\n",
      "总币种数量: 3000\n",
      "\n",
      "前5行数据:\n",
      "  Coin Name    Symbol\n",
      "0  LOLToken     $PEPE\n",
      "1  LOLToken   $GIGGLE\n",
      "2  LOLToken  $MOONWAG\n",
      "3   DogeSun     $MEOW\n",
      "4  ChadCoin     $PEPE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import jieba\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('Meme_Coins_Solana_3000.csv')  # 包含 'Coin Name', 'Symbol' 列\n",
    "\n",
    "print(\"数据概览:\")\n",
    "print(f\"总币种数量: {len(df)}\")\n",
    "print(\"\\n前5行数据:\")\n",
    "print(df[['Coin Name', 'Symbol']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "预处理文本数据...\n",
      "进行文本向量化...\n",
      "文本向量维度: (3000, 100)\n",
      "进行聚类分析...\n",
      "分析各聚类特点...\n",
      "\n",
      "保存完整模型文件...\n",
      "保存轻量级 JSON 模型...\n",
      "✅ 模型文件保存完成!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 自定义 JSON 序列化器来处理 NumPy 数据类型\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.intc, np.intp, np.int8, np.int16, \n",
    "                          np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, np.bool_):\n",
    "            return bool(obj)\n",
    "        return super().default(obj)\n",
    "\n",
    "# 文本预处理函数\n",
    "def preprocess_text(text):\n",
    "    \"\"\"预处理文本，支持中英文\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'[^\\w\\u4e00-\\u9fff]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenize_chinese(text):\n",
    "    \"\"\"中文分词\"\"\"\n",
    "    return ' '.join(jieba.cut(text))\n",
    "\n",
    "def preprocess_combined(row):\n",
    "    \"\"\"组合处理 Coin Name 和 Symbol\"\"\"\n",
    "    name = preprocess_text(row['Coin Name'])\n",
    "    symbol = preprocess_text(row['Symbol'])\n",
    "    \n",
    "    # 如果是中文，进行分词\n",
    "    if any('\\u4e00-\\u9fff' in text for text in [name, symbol]):\n",
    "        name = tokenize_chinese(name)\n",
    "        symbol = tokenize_chinese(symbol)\n",
    "    \n",
    "    combined_text = f\"{name} {symbol}\"\n",
    "    return combined_text\n",
    "\n",
    "# 准备文本数据\n",
    "print(\"\\n预处理文本数据...\")\n",
    "df['combined_text'] = df.apply(preprocess_combined, axis=1)\n",
    "\n",
    "# 文本向量化\n",
    "print(\"进行文本向量化...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['combined_text'])\n",
    "print(f\"文本向量维度: {X.shape}\")\n",
    "\n",
    "# 聚类\n",
    "print(\"进行聚类分析...\")\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "# 分析聚类特征\n",
    "print(\"分析各聚类特点...\")\n",
    "cluster_descriptions = {}\n",
    "\n",
    "for cluster_id in range(4):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    cluster_texts = ' '.join(cluster_data['combined_text'])\n",
    "    \n",
    "    words = cluster_texts.split()\n",
    "    from collections import Counter\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    common_words = [(word, count) for word, count in word_counts.most_common(20) \n",
    "                   if len(word) > 1 and not word.isdigit()]\n",
    "    \n",
    "    theme_keywords = {\n",
    "        '动物系': ['dog', 'cat', 'shib', 'doge', 'kitty', 'pig', 'bull', 'bear', '动物', '狗', '猫'],\n",
    "        '人物系': ['king', 'queen', 'elon', 'people', 'man', 'woman', '国王', '女王', '人物'],\n",
    "        '自然系': ['moon', 'sun', 'earth', 'star', 'planet', '宇宙', '星星', '月亮', '太阳'],\n",
    "        '财富系': ['money', 'cash', 'rich', 'gold', 'diamond', '财富', '金钱', '黄金'],\n",
    "        '科技系': ['ai', 'tech', 'robot', 'cyber', 'quantum', '人工智能', '科技', '机器人']\n",
    "    }\n",
    "    \n",
    "    detected_themes = []\n",
    "    for theme, keywords in theme_keywords.items():\n",
    "        theme_count = sum(1 for word, _ in common_words[:10] if word in keywords)\n",
    "        if theme_count >= 2:\n",
    "            detected_themes.append(theme)\n",
    "    \n",
    "    # 确保所有数据都是 Python 原生类型\n",
    "    cluster_descriptions[cluster_id] = {\n",
    "        'size': int(len(cluster_data)),  # 转换为 Python int\n",
    "        'common_words': [(str(word), int(count)) for word, count in common_words[:8]],  # 确保字符串和整数\n",
    "        'themes': [str(theme) for theme in detected_themes],\n",
    "        'example_coins': [\n",
    "            {\n",
    "                'name': str(coin['Coin Name']),\n",
    "                'symbol': str(coin['Symbol'])\n",
    "            }\n",
    "            for _, coin in cluster_data[['Coin Name', 'Symbol']].head(3).iterrows()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# 保存完整模型文件\n",
    "print(\"\\n保存完整模型文件...\")\n",
    "model_package = {\n",
    "    'metadata': {\n",
    "        'model_type': 'Text_Only_MemeCoin_Classifier',\n",
    "        'features': ['Coin Name', 'Symbol'],\n",
    "        'num_clusters': int(kmeans.n_clusters),  # 转换为 Python int\n",
    "        'language': 'multilingual'\n",
    "    },\n",
    "    'vectorizer': vectorizer,\n",
    "    'kmeans': kmeans,\n",
    "    'cluster_descriptions': cluster_descriptions\n",
    "}\n",
    "\n",
    "joblib.dump(model_package, 'text_only_meme_classifier.pkl')\n",
    "\n",
    "# 保存轻量级 JSON 模型（修复序列化问题）\n",
    "print(\"保存轻量级 JSON 模型...\")\n",
    "lightweight_model = {\n",
    "    'vocabulary': {str(k): int(v) for k, v in vectorizer.vocabulary_.items()},  # 确保字符串键和整数值\n",
    "    'idf': [float(x) for x in vectorizer.idf_],  # 转换为 Python float 列表\n",
    "    'cluster_centers': [[float(y) for y in x] for x in kmeans.cluster_centers_],  # 转换为嵌套的 Python float 列表\n",
    "    'feature_names': [str(name) for name in vectorizer.get_feature_names_out()],  # 确保字符串\n",
    "    'cluster_descriptions': cluster_descriptions,\n",
    "    'model_params': {\n",
    "        'num_clusters': int(kmeans.n_clusters),\n",
    "        'max_features': int(vectorizer.max_features)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 使用自定义编码器保存 JSON\n",
    "with open('lightweight_model.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(lightweight_model, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)\n",
    "\n",
    "print(\"✅ 模型文件保存完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
